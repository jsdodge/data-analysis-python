{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error propagation\n",
    "\n",
    "Python activities to complement [*Measurements and their Uncertainties*](http://www.oupcanada.com/catalog/9780199566334.html) (*MU*), Chapter 4, \"Error propagation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Preliminaries](#Preliminaries)\n",
    "* [Functions of an uncertain variable](#Functions-of-an-uncertain-variable)\n",
    "    * [A function of a distribution is another distribution](#A-function-of-a-distribution-is-another-distribution)\n",
    "        * [Programming notes 1](#Programming-notes-1)\n",
    "    * [Exercise 1](#Exercise-1)\n",
    "* [Functions of many uncertain variables](#Functions-of-many-uncertain-variables)\n",
    "    * [Example: pressure of a van der Waals gas](#Example&#58;-pressure-of-a-van-der-Waals-gas)\n",
    "    * [Exercise 2](#Exercise-2)\n",
    "* [Experimental design](#Experimental-design)\n",
    "    * [Example: density measurement](#Example&#58;-density-measurement)\n",
    "        * [Programming notes 2](#Programming-notes-2)\n",
    "* [Combining measurements](#Combining-measurements)\n",
    "    * [The weighted mean](#The-weighted-mean)\n",
    "        * [Programming notes 3](#Programming-notes-3)\n",
    "    * [Exercise 3](#Exercise-3)\n",
    "* [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "Before proceeding with this notebook you should review the topics from the [previous notebook](3.0-Basic-probability.ipynb) and read *MU* Ch. 4, \"Error propagation,\" with the following [goals](https://wiki.its.sfu.ca/departments/phys-students/index.php/Reading_goals_for_Hughes_and_Hase#Error_propagation) in mind.\n",
    "\n",
    "1. Be able to explain why Eq. (4.7) gives the approximate uncertainty in the single-variable function *Z*(*A*) when there is uncertainty in the argument *A*, and be able to discuss the limitations of this approximation.\n",
    "2. Be able to derive all of the results in Table 4.1 and use Eq. (4.7) in concrete examples.\n",
    "3. Be able to explain why the component uncertainties $\\alpha_Z^A, \\alpha_Z^B, \\alpha_Z^C\\ldots$, add in quadrature to give $\\alpha_Z$ in Eq. (4.10), and recognize (for now) that this expression is restricted to independent, uncorrelated variables (Ch. 7 discusses the reason for this restriction in more depth).\n",
    "4. Be able to explain why Eq. (4.16) gives the approximate uncertainty in the multivariable function $Z\\left(A, B, C,\\ldots\\right)$ when there is uncertainty in the arguments *A*, *B*, *C*,&hellip;, and be able to discuss the limitations of this approximation—here, as in (3) above, it is enough for you to recognize that the variables must be independent and uncorrelated.\n",
    "5. Be able to derive all of the results in Table 4.2 and use Eq. (4.16) in concrete examples.\n",
    "6. Be able to use error propagation methods to identify the dominant uncertainty in an experiment.\n",
    "7. Be able to find the weighted mean and its standard error $\\alpha_\\text{CE}$ for a set of numbers $\\left\\{x_i\\right\\}$ with uncertainties $\\left\\{\\alpha_i\\right\\}$.\n",
    "\n",
    "The following code cell includes previously used initialization commands that we will need here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions of an uncertain variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function of a distribution is another distribution\n",
    "We saw in the [2.0 Basic statistics](2.0-Basic-statistics.ipynb#How-to-interpret-the-mean-±-the-standard-error) notebook that the expression $\\bar{x}\\pm\\hat{\\alpha}$ represents an estimate of the statistical distribution that we expect for repeated identical measurements, typically $P_\\text{DF}(\\bar{x}) = \\mathcal{N}(\\bar{x};\\mu,\\alpha^2)$. The function $\\bar{y} = f(\\bar{x})$ now represents a *different* distribution, $P'_{DF}(\\bar{y})$, that we can relate to $P_\\text{DF}(\\bar{x})$. Usually we can use the linear approximation $f(\\bar{x}+\\Delta)\\approx f(\\bar{x}) + f'(\\bar{x})\\Delta$ discussed in *MU* Sec. 4.1, but it is important to be aware that this approximation is not always valid. The code cell below shows the distribution for $Z = 10^A$ with $A = 2.3\\pm 0.1$, as discussed in *MU* Sec. 4.1.4. The first plot shows that the funtion $Z(A)$ has clear positive curvature; this causes the distribution for $Z(A)$ to become skewed toward higher values. Nonetheless, the procedure described in *MU* Sec. 4.1 yields an accurate estimate of its mean and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programming notes 1\n",
    "We use the NumPy [`around`](https://numpy.org/devdocs/reference/generated/numpy.around.html) function (short for \"array round\") with the option `decimals=-1` to round the mean and standard error of *Z* to the nearest 10, since the format string syntax  only allows us to specify the number of digits to print to the *right* of the decimal place. The statement that prints *Z* is long, so we use the [`\\`](https://docs.python.org/3/reference/lexical_analysis.html#index-6) character to indicate that the `print` statement continues on the next line.\n",
    "\n",
    "We also use the pyplot function [`show`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.show.html) to display each figure in sequence; otherwise each new plot command will be applied to the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed RNG and set simulation parameters\n",
    "random.seed(0)\n",
    "N = 1000\n",
    "A_mean = 2.3\n",
    "A_alpha = 0.1\n",
    "\n",
    "# Simulate distributions\n",
    "A = A_mean + A_alpha*random.randn(N)\n",
    "Z = 10**A\n",
    "\n",
    "# Show the mean and standard deviation for A and Z\n",
    "Z_mean = np.mean(Z)\n",
    "Z_alpha1 = np.std(Z,ddof=1)\n",
    "\n",
    "print(f\"A = {np.mean(A):.1f} ± {np.std(A,ddof=1):.1f}\")\n",
    "print(f\"Z = {np.around(Z_mean, decimals=-1):.0f} ± \\\n",
    "    {np.around(Z_alpha1, decimals=-1):.0f}\")\n",
    "\n",
    "# Plot function\n",
    "A_fun = np.linspace(A_mean - 2*A_alpha, A_mean + 2*A_alpha)\n",
    "plt.plot(A_fun,10**A_fun)\n",
    "plt.xlabel(\"A\")\n",
    "plt.ylabel(\"Z(A)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot distribution for A\n",
    "plt.hist(A, ec='k')\n",
    "plt.xlabel(\"A\")\n",
    "plt.ylabel(\"Occurrences\")\n",
    "plt.show();\n",
    "\n",
    "# Plot distribution for Z\n",
    "plt.hist(Z, ec='k')\n",
    "plt.xlabel(\"Z\")\n",
    "plt.ylabel(\"Occurrences\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "To see how the linear approximation can break down completely, copy the contents of the code cell above into the code cell below, then change `A_alpha = 0.1` to `A_alpha = 0.4`, as discussed at the end of *MU* Sec. 4.1.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell for Exercise 1\n",
    "# Use this cell for your response, adding cells if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions of many uncertain variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: pressure of a van der Waals gas\n",
    "Below we simulate the distribution discussed in *MU* Sec. 4.2.2, for the pressure *P* of a van der Waals gas deduced from measurements of the molar volume *V*<sub>m</sub> and absolute temperature *T*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed RNG and set number of simulations\n",
    "random.seed(0)\n",
    "N = 1000\n",
    "\n",
    "# Molar volume (m^3/mol)\n",
    "Vm_mean = 2e-4\n",
    "Vm_alpha = 0.003e-4\n",
    "Vm = Vm_mean + Vm_alpha*random.randn(N)\n",
    "\n",
    "# Absolute temperature (K)\n",
    "T_mean = 298.0\n",
    "T_alpha = 0.2\n",
    "T = T_mean + T_alpha*random.randn(N)\n",
    "\n",
    "# Assign constants\n",
    "a = 1.408e-1    # m^6 mol^(-2) Pa\n",
    "b = 3.913e-5    # m^3 mol^(-1)\n",
    "R = 8.3145      # J K^(-1) mol(-1)\n",
    "\n",
    "# Compute P and show distribution (in MPa)\n",
    "P  = R*T/(Vm - b) - a/Vm**2\n",
    "\n",
    "plt.hist(P/1e6, ec='k')\n",
    "plt.xlabel(\"Pressure (MPa)\")\n",
    "plt.ylabel(\"Occurrences\");\n",
    "\n",
    "# Print distribution parameters\n",
    "print(f\"P = ({np.mean(P)/1e6:.2f} ± {np.std(P, ddof=1)/1e6:.2f}) MPa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "[Adapted from *MU* Prob. (4.4).] Use `randn` to simulate 1000 measurements of the incident angle $\\theta_\\text{i} = (45.0\\pm 0.1)^\\circ$ and transmitted angle $\\theta_\\text{t} = (34.5\\pm 0.2)^\\circ$ for a plane electromagnetic wave incident on a dielectric surface and polarized in the plane of incidence. Compute\n",
    "\n",
    "$$ R = \\frac{\\tan^2(\\theta_i - \\theta_t)}{\\tan^2(\\theta_i + \\theta_t)}$$\n",
    "\n",
    "for each simulated pair $(\\theta_\\text{i}, \\theta_\\text{t})_k$, and compare the mean and standard deviation of the simulated *R* with the calculus-based error propagation estimate. Plot a histogram of the simulated distribution for *R*.\n",
    "\n",
    "*Note:* Trigonometric functions in NumPy are defined in radians. The NumPy functions [`degrees`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.degrees.html), [`radians`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.radians.html), [`deg2rad`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.deg2rad.html), and [`rad2deg`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.rad2deg.html) convert between radians and degrees. See the NumPy documentation on [mathematical functions](#https://docs.scipy.org/doc/numpy/reference/routines.math.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell for Exercise 2\n",
    "# Use this cell for your response, adding cells if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: density measurement\n",
    "Below we simulate the distribution discussed in *MU* Sec. 4.4, for the relative error in the density of a sphere given measurements of its mass and radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programming notes 2\n",
    "To compare the three distributions we show the histograms as probability densities with common bin edges, and we set the [Patch](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.patches.Patch.html) property [`alpha`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.patches.Patch.html#matplotlib.patches.Patch.set_alpha) to 0.6 to make each histogram semitransparent. We also assign each plot a label with the `label` keyword option, which is used by the [`legend`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.legend.html) function to construct the legend. Previously we set `ec='k'` to show the histogram bars with a black outline, but in this case we return to the default behavior so that the outlines do not interfere with the visibility of the superposed histograms.\n",
    "\n",
    "The total relative error in this simulation (with `random.seed(0)`) is 3.1%, not 3.2% as we would expect from our knowledge of the parent distributions. This is a statistical fluctuation, which you can see by changing the RNG seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed RNG and set simulation parameters\n",
    "random.seed(0)\n",
    "N = 1000\n",
    "\n",
    "m_alpha_rel = 0.01\n",
    "r_alpha_rel = 0.01\n",
    "\n",
    "# Simulate mass, radius, density (relative to mean)\n",
    "m_rel = 1 + m_alpha_rel*random.randn(N)\n",
    "r_rel = 1 + r_alpha_rel*random.randn(N)\n",
    "\n",
    "rho_rel = m_rel/r_rel**3\n",
    "\n",
    "# Show distributions\n",
    "edges = np.arange(-0.1, 0.11, 0.01)\n",
    "plt.hist(m_rel - 1, bins=edges, density=True,\n",
    "         alpha=0.6, label=\"Mass only\")\n",
    "plt.hist(r_rel**-3 - 1, bins=edges, density=True,\n",
    "         alpha=0.6, label=\"Radius only\")\n",
    "plt.hist(rho_rel - 1, bins=edges, density=True,\n",
    "         alpha=0.6, label=\"Total\")\n",
    "plt.xlabel(\"Relative deviation from mean\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend();\n",
    "\n",
    "# Print total relative error\n",
    "print(f\"Relative error = {np.std(rho_rel, ddof=1):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The weighted mean\n",
    "In the following example we simulate a set of fifteen measurements based on those reported in *MU* Table 2.1, and separate them into one group of five (set *A*) and another group of ten (set *B*). We then find their respective means and standard errors and combine them in a weighted average.\n",
    "\n",
    "Of course we could also just take the mean and standard error of *all* of the measurements in sets *A* and *B*, since we have the raw data—the weighted mean is really only necessary if we must rely on the reported means and standard errors. We compare the results of the two methods below. Typically they will be slightly different, but they should be close if the original measurements are limited only by statistical uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programming notes 3\n",
    "After generating sets *A* and *B* and computing their respective means and standard errors, we use the NumPy [`array`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html) function to organize them into two [NumPy arrays](https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html). We have not needed to use the `array` function yet, but you have already used NumPy arrays, since this is what the functions `zeros`, `rand`, `randn`, and `arange` return. NumPy arrays support a variety of mathematical array operations that are not defined for conventional Python arrays. For example, neither division nor exponentiation are defined on Python [lists](https://docs.python.org/3/tutorial/introduction.html#lists), so the expression `w = 1/period_AB_alpha**2` will generate an error with the definition `period_AB_alpha = [period_A_alpha, period_B_alpha]`.\n",
    "\n",
    "After computing the weighted average directly, we compute it with the NumPy [`average`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.average.html) function and confirm that we get the same result.\n",
    "\n",
    "Finally, we combine sets *A* and *B* with the NumPy [`concatenate`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html) function, then compute its mean and standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seed RNG and set simulation parameters\n",
    "random.seed(0)\n",
    "period_mean = 9.93\n",
    "period_std = 0.4\n",
    "\n",
    "N_A = 5\n",
    "N_B = 10\n",
    "\n",
    "# Simulate data\n",
    "period_A = period_mean + period_std*random.randn(N_A)\n",
    "period_B = period_mean + period_std*random.randn(N_B)\n",
    "\n",
    "period_A_mean = np.mean(period_A)\n",
    "period_A_alpha = np.std(period_A, ddof=1)/np.sqrt(N_A)\n",
    "\n",
    "period_B_mean = np.mean(period_B)\n",
    "period_B_alpha = np.std(period_B, ddof=1)/np.sqrt(N_B)\n",
    "\n",
    "print(f\"Period, set A: ({period_A_mean:.2f} ± {period_A_alpha:.2f}) s\")\n",
    "print(f\"Period, set B: ({period_B_mean:.2f} ± {period_B_alpha:.2f}) s\")\n",
    "\n",
    "# Compute weighted mean directly\n",
    "period_AB_mean = np.array([period_A_mean, period_B_mean])\n",
    "period_AB_alpha = np.array([period_A_alpha, period_B_alpha])\n",
    "\n",
    "w = 1/period_AB_alpha**2\n",
    "period_mean_weighted = np.sum(w*period_AB_mean)/np.sum(w)\n",
    "alpha_CE = np.sqrt(1/np.sum(w))\n",
    "\n",
    "print(f\"Period, weighted: ({period_mean_weighted:.2f} ± {alpha_CE:.2f}) s\")\n",
    "\n",
    "# Compute weighted mean with average function\n",
    "period_mean_weighted_alt = np.average(period_AB_mean, weights=w)\n",
    "print(f\"Period, weighted (alt): ({period_mean_weighted_alt:.2f} ± {alpha_CE:.2f}) s\")\n",
    "\n",
    "# Compute mean and standard error for combined data\n",
    "period_all = np.concatenate((period_A, period_B))\n",
    "period_all_mean = np.mean(period_all)\n",
    "period_all_alpha = np.std(period_all, ddof=1)/np.sqrt(len(period_all))\n",
    "print(f\"Period, sets A and B: ({period_all_mean:.2f} ± {period_all_alpha:.2f}) s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "[Adapted from *MU* Prob. (4.10).]  Combine the following measurements of the speed of light and report the result.\n",
    "\n",
    "| Measurement (10<sup>8</sup> m/s) | Standard error (10<sup>8</sup> m/s) |\n",
    "|:--------------------------------:|:-----------------------------------:|\n",
    "| 3.03 | 0.04 |\n",
    "| 2.99 | 0.03 |\n",
    "| 2.99 | 0.02 |\n",
    "| 3.00 | 0.05 |\n",
    "| 3.05 | 0.04 |\n",
    "| 2.97 | 0.02 |\n",
    "\n",
    "If another student then reports $c = (3.0 \\pm 0.3)\\times 10^8~\\text{m}/\\text{s}$, is there any change in the newly combined measurement? What would you do if a further student reported $c = (4.01 \\pm 0.01)\\times 10^8~\\text{m}/\\text{s}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell for Exercise 3\n",
    "# Use this cell for your response, adding cells if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of what you should be able to do after completing this notebook.\n",
    "* Use the [`around`](https://numpy.org/devdocs/reference/generated/numpy.around.html) NumPy function to round numbers to different levels of precision.\n",
    "* Use the [`\\`](https://docs.python.org/3/reference/lexical_analysis.html#index-6) character to explicitly break a statement across multiple lines. (Note that it is not always necessary to include the `\\` character to do this; expressions with parentheses, square brackets, or curly braces may be continued [implicitly](https://docs.python.org/3/reference/lexical_analysis.html#implicit-line-joining) without it.)\n",
    "* Use the [`show`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.show.html) pyplot function to display a figure and begin a new one.\n",
    "* Recognize that error propagation is a simplified method for estimating the functional image of a distribution.\n",
    "* Overlay multiple histograms by setting the [`alpha`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.patches.Patch.html#matplotlib.patches.Patch.set_alpha) transparency property as a keyword option in pyplot.\n",
    "* Add a label to a plot element with the `label` keyword option, and use the [`legend`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.legend.html) function in pyplot to add a legend to a plot.\n",
    "* Recognize the difference between a [NumPy array](https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html) and a Python [list](https://docs.python.org/3/tutorial/introduction.html#lists).\n",
    "* Use the NumPy [`array`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html) function to create a NumPy array.\n",
    "* Use the NumPy [`average`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.average.html) function to compute a weighted average.\n",
    "* Use the NumPy [`concatenate`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html) function to concatenate two or more NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### About this notebook\n",
    "Notebook by J. S. Dodge, 2019. Available from [SFU GitLab](https://gitlab.rcg.sfu.ca/jsdodge/data-analysis-python). The notebook text is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. See more at [Creative Commons](http://creativecommons.org/licenses/by-nc-nd/4.0/). The notebook code is open source under the [MIT License](https://opensource.org/licenses/MIT)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
