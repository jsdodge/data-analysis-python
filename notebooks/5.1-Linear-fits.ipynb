{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and modeling (cont'd)\n",
    "\n",
    "Python activities to complement material on linear fits in [*Measurements and their Uncertainties*](https://www.oupcanada.com/catalog/9780199566334.html) (*MU*), Chapter 5, \"Data visualization and reduction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Preliminaries](#Preliminaries)\n",
    "* [Linear fits](#Linear-fits)\n",
    "    * [Explicit formulas for uniform uncertainty](#Explicit-formulas-for-uniform-uncertainty)\n",
    "        * [Parameter estimates](#Parameter-estimates)\n",
    "        * [Parameter uncertainties](#Parameter-uncertainties)\n",
    "    * [Exercise 2](#Exercise-2)\n",
    "    * [Linear fits with `polyfit`](#Linear-fits-with-polyfit)\n",
    "        * [Programming notes 1](#Programming-notes-1)\n",
    "    * [Exercise 3](#Exercise-3)\n",
    "* [Residual analysis](#Residual-analysis)\n",
    "    * [Example: Residuals for Ohm's law measurement](#Example&#58;-Residuals-for-Ohm's-law-measurement)\n",
    "        * [Programming notes 2](#Programming-notes-2)\n",
    "    * [Exercise 4](#Exercise-4)\n",
    "* [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "Before proceeding with this notebook you should review the topics from the [previous notebook](5.0-Visualization-and-modeling.ipynb).\n",
    "\n",
    "The following code cell includes previously used initialization commands that we will need here. The next cell imports data used in the [previous notebook](5.0-Visualization-and-modeling.ipynb) and redefines some of the variables used there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "current, voltage, alpha_voltage = np.genfromtxt(\"data/resistance.csv\", skip_header=1, delimiter=\",\", unpack=True)\n",
    "\n",
    "# Define separate current vector for model\n",
    "current_model = np.linspace(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear fits\n",
    "When two measurement variables such as $x$ and $y$ satisfy a functional relationship such as\n",
    "\n",
    "$$ y = f(x;m,c) = mx + c, \\label{eq:line}\\tag{1}$$\n",
    "\n",
    "we are typically interested in the values for $m$ and $c$ that offer the best fit to our measurements. Here, \"best\" means the values of $m$ and $c$ that minimize\n",
    "\n",
    "$$\\chi^2(m,c;\\{x_k\\},\\{y_k\\},\\{\\alpha_k\\}) = \\sum_{k=1}^N\\frac{[y_k - (mx_k +  c)]^2}{\\alpha_k^2}, \\label{eq:lsq}\\tag{2}$$\n",
    "\n",
    "where each $y_k$ is a noisy measurement at $x_k$ with standard error $\\alpha_k$. Note the asymmetry here: all the  uncertainty is in $y$, and $x$ is assumed to be *known*. Consequently, it is important that you associate the dependent variable with the measurement that has the dominant uncertainty. See *MU* Sec. 9.1 for the case when the uncertainty in $x$ can not be ignored. \n",
    "\n",
    "The values $\\hat{m}$ and $\\hat{c}$ that minimize Eq.&nbsp;(\\ref{eq:lsq}) are known as the *least-squares fit parameters* for Eq.&nbsp;(\\ref{eq:line}). (Recall that the \"hat\" notation for $\\hat{m}$ and $\\hat{c}$ indicates that they are *estimates* of $m$ and $c$, given the data $\\{x_k,y_k\\}$.) As discussed in *MU*, Eq.&nbsp;(\\ref{eq:lsq}) follows from *maximizing the likelihood* that you would obtain your measurements, assuming that they satisfy Eq.&nbsp;(\\ref{eq:line}) with a measurement uncertainty $\\alpha_k$ for each $y_k$. We can of course consider more general, nonlinear relationships among measurent variables, but linear relationships have some advantages that are worth exploring in depth, as we will see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit formulas for uniform uncertainty\n",
    "\n",
    "#### Parameter estimates\n",
    "Let us restrict ourselves to the case of uniform uncertainty for now, so that $\\alpha_k = \\alpha$ for all $k$. Eq.&nbsp;([2](#mjx-eqn-eq:lsq)) then simplifies to\n",
    "\n",
    "$$\n",
    "\\chi^2(m,c;\\{x_k\\},\\{y_k\\},\\alpha) = \\frac{1}{\\alpha^2}\\sum_{k=1}^N[y_k - (mx_k +  c)]^2, \\label{eq:lsquniform}\\tag{3}\n",
    "$$\n",
    "\n",
    "which we can differentiate to find the extremal conditions\n",
    "\n",
    "\\begin{align}\n",
    "\\left.\\frac{\\partial{\\chi^2}}{\\partial m}\\right|_{\\hat{m},\\hat{c}} &= -\\frac{2}{\\alpha^2}\\sum_{k=1}^N[y_k - (\\hat{m}x_k + \\hat{c})]x_k = 0,\\\\\n",
    "\\left.\\frac{\\partial{\\chi^2}}{\\partial c}\\right|_{\\hat{m},\\hat{c}} &= -\\frac{2}{\\alpha^2}\\sum_{k=1}^N[y_k - (\\hat{m}x_k + \\hat{c})] = 0.\n",
    "\\end{align}\n",
    "\n",
    "Solving this system of equations for $\\hat{m}$ and $\\hat{c}$ give *MU* Eqs.&nbsp;(5.1) and (5.2) (rewritten for consistency with the notation here),\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{c} &= \\frac{\\left(\\sum_k x_k^2\\right)\\left(\\sum_k y_k\\right) - \\left(\\sum_k x_k\\right)\\left(\\sum_k x_k y_k\\right)}{\\Delta}, \\label{eq:c-hat}\\tag{4}\\\\\n",
    "\\hat{m} &= \\frac{N\\sum_k x_k y_k - \\left(\\sum_k x_k\\right)\\left(\\sum_k y_k\\right)}{\\Delta},\\quad\\text{with}\\\\\n",
    "\\Delta &= N\\sum_k x_k^2 - \\left(\\sum_k x_k\\right)^2. \\label{eq:m-hat}\\tag{5}\n",
    "\\end{align}\n",
    "\n",
    "These equations express $\\hat{m}$ and $\\hat{c}$ *as unique, explicit functions of the data* that will *automatically* minimize $\\chi^2$ in Eq.&nbsp;(\\ref{eq:lsquniform}) for *any* values of $\\{x_k, y_k\\}$. This is one of the chief advantages of a linear fit: the least-squares fit parameters may be determined unambiguously from the data, without a search algorithm. It is important to recognize, though, that these equations will yield values even when $\\{x_k, y_k\\}$ do *not* satisfy a linear relationship, so we must always evaluate the quality of the fit before assigning much significance to the best-fit parameters obtained from it.\n",
    "\n",
    "#### Parameter uncertainties\n",
    "\n",
    "Now that we have expressed $\\hat{m}$ and $\\hat{c}$ as functions of $\\{x_k, y_k\\}$, we can use standard error propagation to compute the uncertainties in $\\hat{m}$ and $\\hat{c}$. To do this, we must treat each measurement $y_k$ as an independent variable in the functions $\\hat{m}$ and $\\hat{c}$, all with standard error $\\alpha$. Recall that we have assumed the $x_k$ variables as known, so we do not need to propagate their uncertainty.\n",
    "\n",
    "\\begin{align}\n",
    "\\alpha_\\hat{m}^2 &= \\sum_{l = 1}^N\\left(\\frac{\\partial\\hat{m}}{\\partial y_l}\\right)^2\\alpha^2 = \\frac{\\alpha^2}{\\Delta^2}\\sum_{l = 1}^N\\left(Nx_l -  \\sum_{k=1}^N x_k\\right)^2 = \\frac{N}{\\Delta}\\alpha^2,\\\\\n",
    "\\alpha_\\hat{c}^2 &= \\sum_{l = 1}^N\\left(\\frac{\\partial\\hat{c}}{\\partial y_l}\\right)^2\\alpha^2 = \\frac{\\alpha^2}{\\Delta^2}\\sum_{l = 1}^N\\left(\\sum_{k=1}^N x_k^2 - x_l\\sum_{k=1}^N x_k\\right)^2 = \\frac{\\sum_{k=1}^N x_k^2}{\\Delta}\\alpha^2.\n",
    "\\end{align}\n",
    "\n",
    "Taking the square root of these expressions, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\alpha_{\\hat{m}} &= \\alpha\\sqrt{\\frac{N}{\\Delta}}, & \\alpha_{\\hat{c}} &= \\alpha\\sqrt{\\frac{\\sum_{k=1}^N x_k^2}{\\Delta}}, \\label{eq:alpha-m-c}\\tag{6}\n",
    "\\end{align}\n",
    "\n",
    "which are equivalent to *MU* Eqs.&nbsp;(5.3) and (5.4) if we substitute $\\alpha = \\alpha_\\text{CU}$, where\n",
    "\n",
    "$$\n",
    "\\alpha_{CU} = \\sqrt{\\frac{1}{N-2}\\sum_{k=1}^{N}[y_k - (\\hat{m}x_k + \\hat{c})]^2} \\label{eq:alpha-CU}\\tag{7}\n",
    "$$\n",
    "\n",
    "is known as the *common uncertainty*. The distinction here is that $\\alpha$ is assumed to be *known*, just as we assume $\\{x_k\\}$ known, while we determine $\\alpha_\\text{CU}$ from the same data that we use to obtain the fit. \n",
    "\n",
    "Just as the data will vary from one set of measurements to another, so will $\\alpha_\\text{CU}$, while $\\alpha$ remains fixed.  If your estimate for $\\alpha$ is accurate, then the expectation of $\\alpha_\\text{CU}$ (ie, the average over $N\\rightarrow\\infty$ data sets) will be\n",
    "\n",
    "$$\n",
    "\\left\\langle \\alpha_\\text{CU}^2\\right\\rangle = \\alpha^2,\n",
    "$$\n",
    "\n",
    "so the difference between $\\alpha_\\text{CU}$ and $\\alpha$ is usually small. But if your estimate for $\\alpha$ is *inaccurate*, then the difference between $\\alpha_\\text{CU}$ and $\\alpha$ can be large, so comparing the two provides a good consistency check. The standard way to make this comparison is to compute\n",
    "\n",
    "$$\n",
    "\\chi^2_\\text{min} = \\chi^2(\\hat{m}, \\hat{c}) = \\frac{1}{\\alpha^2}\\sum_{k=1}^N[y_k - (\\hat{m}x_k +  \\hat{c})]^2 = \\frac{\\alpha_{CU}^2}{\\alpha^2}(N-2),\n",
    "$$\n",
    "\n",
    "and check that $\\chi^2_\\text{min}\\approx N - 2$. We compare to $N-2$ here because there are two free fit parameters, $\\hat{m}$ and $\\hat{c}$â€”in general, for a fit with $p$ fit parameters, we would compare to $N-p$. For more sophisticated ways to evaluate a fit, see the [Residual analysis](#Residual-analysis) section below.\n",
    "\n",
    "Now let's compute the linear fit parameters to the current-voltage data in the [Demonstrating Ohm's law](5.0-Visualization-and-modeling.ipynb#Example:-Demonstrating-Ohm's-law) example. We compute the parameter uncertainty using both the given uncertainty $\\alpha$ and the calculated common uncertainty $\\alpha_\\text{CU}$; since they are close, you would normally report the values using $\\alpha$. You should use $\\alpha_\\text{CU}$ only if you believe that it provides the best available estimate of your measurement uncertainty. Once we obtain the best-fit parameters, we plot the data (using markers) together with the fit (as a line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate intermediate expressions\n",
    "# Number of terms\n",
    "N = len(current)\n",
    "\n",
    "# Uniform uncertainty\n",
    "alpha = alpha_voltage[0]\n",
    "\n",
    "# Sums over x and y\n",
    "sx = np.sum(current)\n",
    "sy = np.sum(voltage)\n",
    "\n",
    "# Sums over x**2 and x*y\n",
    "sx2 = np.sum(current**2)\n",
    "sxy = np.sum(current * voltage)\n",
    "\n",
    "# Evaluate Delta\n",
    "Delta = N * sx2 - sx**2\n",
    "\n",
    "# Put it all together for m_hat and c_hat\n",
    "c_hat = (sx2 * sy - sx * sxy) / Delta\n",
    "m_hat = (N * sxy - sx * sy) / Delta\n",
    "\n",
    "# Compute standard error for m_hat and c_hat\n",
    "alpha_c_hat = alpha * np.sqrt(sx2 / Delta)\n",
    "alpha_m_hat = alpha * np.sqrt(N / Delta)\n",
    "\n",
    "# Compute chi-squared and common uncertainty for best-fit parameters\n",
    "chi2fit = np.sum(((voltage - (m_hat * current + c_hat)) / alpha) ** 2)\n",
    "alpha_cu = alpha * np.sqrt((1 / (N - 2)) * chi2fit)\n",
    "\n",
    "# Recompute standard error for m_hat and c_hat using common uncertainty\n",
    "alpha_c_hat_cu = alpha_cu * np.sqrt(sx2 / Delta)\n",
    "alpha_m_hat_cu = alpha_cu * np.sqrt(N / Delta)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"Intercept estimate with given uncertainty: ({1000*c_hat:.0f} Â± {1000*alpha_c_hat:.0f}) ÂµV\")\n",
    "print(f\"Slope estimate with given uncertainty: ({1000*m_hat:.2f} Â± {1000*alpha_m_hat:.2f}) Î©\")\n",
    "print()\n",
    "print(f\"Intercept estimate with common uncertainty: ({1000*c_hat:.0f} Â± {1000*alpha_c_hat_cu:.0f}) ÂµV\")\n",
    "print(f\"Slope estimate with common uncertainty: ({1000*m_hat:.2f} Â± {1000*alpha_m_hat_cu:.2f}) Î©\")\n",
    "print()\n",
    "print(f\"Chi-squared for best-fit parameters: {chi2fit:.1f}\")\n",
    "print(f\"Degrees of freedom (N-2): {N-2:d}\")\n",
    "print(f\"Given uncertainty: {1000*alpha:.0f} ÂµV\")\n",
    "print(f\"Common uncertainty: {1000*alpha_cu:.0f} ÂµV\")\n",
    "print()\n",
    "\n",
    "# Plot data as markers\n",
    "plt.plot(current, voltage, \"o\")\n",
    "\n",
    "# Overlay fit as a line\n",
    "plt.plot(current_model, m_hat * current_model + c_hat, \"-\")\n",
    "\n",
    "# Format plot\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 10)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.xlabel(r\"Current ($\\mu$A)\", fontsize=12)\n",
    "plt.ylabel(\"Voltage (mV)\", fontsize=12)\n",
    "\n",
    "plt.legend([\"Data\", \"Fit\"], fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercise 2\n",
    "The following cell includes code to import data from the [NIST Statistical Reference Database](https://www.itl.nist.gov/div898/strd/index.html) into the variables `x` and `y` and plots it. The data is taken from a NIST study that involved an ozone sensor calibration; the `y` variable corresponds to the ozone concentration (in nmol/mol) measured by the sensor  of a NIST customer, and the `x` variable corresponds to the measurement with the NIST sensor.  The `y` data corresponds to the first column in the data file, so we list it first in the output of [`genfromtxt`](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html). No measurement uncertainty is provided for this data, so it is appropriate to use the common uncertainty $\\alpha_\\text{CU}$ as an estimate. Some of the measurements are repeated for the same (or very similar) value of `x`. Use *MU* Eqs. (5.1)â€“(5.6) to compute the least-squares best-fit parameters $\\hat{m}$ and $\\hat{c}$ for the model $y=mx+c$, the common uncertainty $\\alpha_\\text{CU}$, and the uncertainties $\\alpha_\\hat{m}$ and $\\alpha_\\hat{c}$ in the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell for Exercise 2\n",
    "# Use this cell for your response, adding cells if necessary.\n",
    "\n",
    "# Load data\n",
    "y, x = np.genfromtxt(\"https://www.itl.nist.gov/div898/strd/lls/data/LINKS/DATA/Norris.dat\", skip_header=60, unpack=True)\n",
    "\n",
    "# Plot data\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.xlabel(\"NIST sensor\")\n",
    "plt.ylabel(\"Customer sensor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear fits with `polyfit`\n",
    "\n",
    "First, a word of warning: NumPy currently (as of v1.25) provides no less than three (!) different ways to fit data with a polynomial, all with slightly different features:\n",
    "* [`numpy.polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html), which we use in these notebooks, is considered a [\"legacy\"](https://numpy.org/doc/stable/reference/routines.polynomials.html#documentation-for-legacy-polynomials) function by NumPy, but is the only one that provides information about the parameter uncertainties.\n",
    "* [`numpy.polynomial.polynomial.polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.polyfit.html#numpy.polynomial.polynomial.polyfit) is a newer version of `polyfit` that NumPy recommends, but it does not yet include an option to return parameter uncertainty information. This is a known [issue](https://github.com/numpy/numpy/issues/20871) that should be addressed in a future version of NumPy, but until then we will have to rely on `numpy.polyfit`.\n",
    "* [`numpy.polynomial.Polynomial.fit`](https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.html#numpy.polynomial.polynomial.Polynomial.fit) is a method of the [`Polynomial`](https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.html) class, which provides an object-oriented interface for doing with polynomial fits. Like `numpy.polynomial.polynomial.polyfit`, it lacks the option to return parameter uncertainty information.\n",
    "\n",
    "The [`polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) function that will fit data with a polynomial model of order $p$,\n",
    "\n",
    "$$\n",
    "y = a_0 x^p + a_1 x^{p-1} + \\ldots + a_{p-1}x + a_p.\n",
    "$$\n",
    "\n",
    "While this is clearly nonlinear in $x$, it is linear in the coefficients $\\{a_k\\}$, which allows us to determine the best least-squares fit parameters $\\{\\hat{a}_k\\}$ through an analysis similar to the one we developed for a fit to a line.\n",
    "\n",
    "The code cell below shows how to use [`polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) to compute $\\hat{m}$, $\\hat{c}$, $\\alpha_\\hat{m}$, and $\\alpha_\\hat{c}$ for the [Demonstrating Ohm's law](5.0-Visualization-and-modeling.ipynb#Example:-Demonstrating-Ohm's-law) example.\n",
    "\n",
    "#### Programming notes 1\n",
    "\n",
    "As described in the [`polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) documentation, the first three parameters correspond to the `x` data, the `y` data, and the polynomial degree `deg`. The option `w=1 / alpha_voltage` weights each residual, $r_k = y_k - (mx_k + c)$, by $1/\\alpha_k$, and the option `cov = 'unscaled'` will cause `polyfit` to use these weights when calculating the parameter uncertainties. (Note that the $w_k = 1/\\alpha_k$ definition of the term \"weights\" in `polyfit` is [different from standard statistical usage](https://github.com/numpy/numpy/issues/5261), where $w_k = 1/\\alpha_k^2$.) To use the common uncertainty to compute the parameter uncertainties, set `cov=True`. \n",
    "\n",
    "Confirm that the results for $\\alpha_{\\hat{m}}$ and $\\alpha_{\\hat{c}}$ are the same as those obtained earlier through explicit computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data using known parameter uncertainties\n",
    "p, V = np.polyfit(current, voltage, 1, w=1 / alpha_voltage, cov=\"unscaled\")\n",
    "\n",
    "# Fit the data and use fit residuals to estimate parameter uncertainties\n",
    "p_scaled, V_scaled = np.polyfit(current, voltage, 1, cov=True)\n",
    "\n",
    "# Print results\n",
    "print(f\"Intercept estimate: ({1000*p[1]:.0f} Â± {1000*np.sqrt(V[1][1]):.0f}) ÂµV\")\n",
    "print(f\"Slope estimate: ({1000*p[0]:.2f} Â± {1000*np.sqrt(V[0][0]):.2f}) Î©\")\n",
    "print(f\"Intercept estimate (scaled): ({1000*p_scaled[1]:.0f} Â± {1000*np.sqrt(V_scaled[1][1]):.0f}) ÂµV\")\n",
    "print(f\"Slope estimate (scaled): ({1000*p_scaled[0]:.2f} Â± {1000*np.sqrt(V_scaled[0][0]):.2f}) Î©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercise 3\n",
    "The following cell downloads and plots the same data from the [NIST Statistical Reference Database](https://www.itl.nist.gov/div898/strd/index.html) that you used for [Exercise 2](#Exercise-2). Use [`polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) to compute the least-squares best-fit parameters $\\hat{m}$ and $\\hat{c}$ and their respective (scaled) uncertainties, $\\alpha_\\hat{m}$ and $\\alpha_\\hat{c}$, for the model $y=mx+c$. Assign these values to variable names that are different from the ones you used in [Exercise 2](#Exercise-2), and confirm that the results from [`polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) are the same as those given in [Exercise 2](#Exercise-2) by explicit computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell for Exercise 3\n",
    "# Use this cell for your response, adding cells if necessary.\n",
    "\n",
    "y, x = np.genfromtxt(\"https://www.itl.nist.gov/div898/strd/lls/data/LINKS/DATA/Norris.dat\", skip_header=60, unpack=True)\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.xlabel(\"NIST sensor\")\n",
    "plt.ylabel(\"Customer sensor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Residuals for Ohm's law measurement\n",
    "\n",
    "The code cell below shows how to add a residual plot to the main plot for the [Demonstrating Ohm's law](5.0-Visualization-and-modeling.ipynb#Example:-Demonstrating-Ohm's-law) example. Here are some things to look for in a residual plot.\n",
    "* The residuals should look random and consistent with a Gaussian distribution.\n",
    "    * A clear pattern in the residuals is a sign of systematic error that ideally should be fixed in the experiment, but could be accommodated by revising the model function.\n",
    "    * Outliers often indicate unreliability in your procedure; try to understand how it happened and take another data set if time allows\n",
    "* The normalized residuals should have a variance close to one.\n",
    "    * A large discrepancy between the variance of the residuals and your estimated measurement variance is worth revisiting, since it often indicates an error in the estimate of $\\alpha$. If you can not identify the source of the discrepancy, you might consider scaling the measurement uncertainy.\n",
    "\n",
    "#### Programming notes 2\n",
    "\n",
    "So far, we have been using the [`pyplot`](https://matplotlib.org/stable/tutorials/introductory/pyplot.html) interface to Matplotlib, which is designed for making simple plots interactively. For more complex plots, it is preferable to use the [`explicit \"Axes\" interface`](https://matplotlib.org/stable/users/explain/api_interfaces.html#the-explicit-axes-interface), also known as the object-oriented interface, which we introduce here.\n",
    "\n",
    "After computing the model curve and the fit residuals in the cell below, we use the [`subplots`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html) function to create two plot axes within a single figure. This function returns two outputs, which we assign to the variables `fig` and `axs`. The `fig` variable represents an instance of the [`Figure`](https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure) object, which contains all the other figure elements. The `axs` variable is a NumPy array that contains instances of the [`Axes`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.html) object, each associated with a different plot within the figure. The first two positional arguments of `subplots` specify the number of rows and columns in the array, so `plt.subplots(2, 1)` returns a figure with 2 rows and 1 column of plot axes, with the top plot assigned to `axs[0]` and the bottom plot assigned to `axs[1]`. Setting `sharex=True` causes the two subplots to share a common x-axis and shows the x tick labels only on the bottom subplot. Setting `height_ratios=[3, 1]` makes the top subplot three times as high as the bottom one.\n",
    "\n",
    "Now we can direct plotting separate commands to each of the two `Axes` instances. The expression `axs[0].errorbar(...)`, for example, creates an `errorbar` plot in the top `Axes`. The next expression, `axs[0].plot(...)`, shows the fitted model curve. The syntax for setting the axis ranges and formatting the axis labels is a little different from that of `pyplot`: instead of `plt.ylim(...)`, for example, we use `axs[0].set_ylim(...)`. Once we have completed the top panel, we use similar commands, preceded by `axs[1]`, to format the bottom panel. We introduce the [`axhline`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.axhline.html) to create a horizontal dotted black line at $y = 0$, which is the baseline for the fit residuals. We also include a newline character, `\\n`, in y-axis label of the bottom plot to reduce its width. Once we are finished, we call `plt.show()` to display the plot, just as we do with the `pyplot` interface.\n",
    "\n",
    "For more details on how to use the object-oriented interface, see the Matplotlib tutorials on [Working with multiple figures and axes](https://matplotlib.org/stable/tutorials/introductory/pyplot.html#working-with-multiple-figures-and-axes) and  [High-level methods for making grids](https://matplotlib.org/stable/tutorials/intermediate/arranging_axes.html#high-level-methods-for-making-grids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the current range and compute the model curve\n",
    "current_range = [0, 100]\n",
    "current_model = np.linspace(current_range[0], current_range[1])\n",
    "voltage_model = m_hat * current_model + c_hat\n",
    "\n",
    "# Compute the measurement residuals\n",
    "residuals = voltage - (m_hat * current + c_hat)\n",
    "\n",
    "# Create figure with 2 rows and 1 column of plot axes, with shared x-axes and a 3:1 height ratio between the top and bottom panel\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, height_ratios=[3, 1])\n",
    "\n",
    "# Plot data in the top panel as black dots\n",
    "axs[0].errorbar(current, voltage, yerr=alpha, fmt=\"k.\")\n",
    "\n",
    "# Plot fit in the top panel as a red line\n",
    "axs[0].plot(current_model, voltage_model, \"r-\")\n",
    "\n",
    "# Format top panel: set y-axis range and add y-axis label\n",
    "# The x-axis is shared with the bottom panel, so it is unnecessary to set it here\n",
    "axs[0].set_ylim(0, 10)\n",
    "axs[0].set_ylabel(\"Voltage (mV)\")\n",
    "\n",
    "# Plot residuals in the bottom panel as black dots\n",
    "axs[1].plot(current, residuals / alpha, \"k.\")\n",
    "\n",
    "# Show zero line in the bottom panel as a black dotted line\n",
    "axs[1].axhline(0, color=\"k\", linestyle=\":\")\n",
    "\n",
    "# Format bottom panel: set axis ranges and add labels to x-axis and y-axis\n",
    "axs[1].set_xlim(current_range[0], current_range[1])\n",
    "axs[1].set_ylim(-2, 2)\n",
    "axs[1].set_xlabel(\"Current (ÂµA)\")\n",
    "axs[1].set_ylabel(\"Normalized\\nresidual\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Following the example above, plot the linear fit from [Exercise 2](#Exercise-2) together with the normalized residuals, using $\\alpha_\\text{CU}$ as the normalization constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cell for Exercise 4\n",
    "# Use this cell for your response, adding cells if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Here is a list of what you should be able to do after completing this notebook.\n",
    "\n",
    "* Explain the significance of $m, c, x_k, y_k$, and $\\alpha_k$ in Eq.&nbsp;(2).\n",
    "* Explain how Eq.&nbsp;(2) is used to fit a theoretical model to experimental data.\n",
    "* Use Eqs.&nbsp;(4)â€“(7) to compute the parameters and parameter uncertainties of a linear fit when the experimental uncertainty is uniform.\n",
    "* Compute $\\chi^2_\\mathrm{min}$ for a linear fit and use it to evaluate the fit quality.\n",
    "* Use [`polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) to compute the parameters and parameter uncertainties of a linear fit when the experimental uncertainty is uniform.\n",
    "* Use residual analysis to evaluate the quality of a fit.\n",
    "* Use the [`explicit \"Axes\" interface`](https://matplotlib.org/stable/users/explain/api_interfaces.html#the-explicit-axes-interface) to create a figure that includes experimental data with errorbars and a theoretical fit to the data in one panel, and a residual plot in a second panel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### About this notebook\n",
    "Â© J. Steven Dodge, 2020. The notebook text is licensed under CC BY 4.0. See more at [Creative Commons](https://creativecommons.org/licenses/by/4.0/). The notebook code is open source under the [MIT License](https://opensource.org/licenses/MIT)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
